import streamlit as st
import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta, timezone
import time
from openai import OpenAI
import logging
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
import threading
from typing import Dict, List, Any, Tuple, Optional
import json
import concurrent.futures
import os
import schedule
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# APIé…ç½®
OPENAI_API_KEY = "xxx"  # æ›´æ–°ä¸ºè‡ªå·±åœ¨tu-ziä¸­çš„API
BINANCE_API_URL = "https://api-gcp.binance.com"  # æ›´æ–°ä¸ºå®˜æ–¹æ¨èçš„ç°è´§APIç«¯ç‚¹
BINANCE_FUTURES_URL = "https://fapi.binance.com"

client = OpenAI(api_key=OPENAI_API_KEY, base_url="https://api.tu-zi.com/v1")

# æ—¶é—´å‘¨æœŸé…ç½®
TIMEFRAMES = {
    "5m": {"interval": "5m", "name": "5åˆ†é’Ÿ", "weight": 0.1},
    "15m": {"interval": "15m", "name": "15åˆ†é’Ÿ", "weight": 0.15},
    "1h": {"interval": "1h", "name": "1å°æ—¶", "weight": 0.25},
    "4h": {"interval": "4h", "name": "4å°æ—¶", "weight": 0.25},
    "1d": {"interval": "1d", "name": "æ—¥çº¿", "weight": 0.25}
}

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .main {
        background-color: #0e1117;
    }
    div.stButton > button {
        width: 100%;
        background-color: #FF4B4B;
        color: white;
        border-radius: 10px;
        padding: 0.8rem 1rem;
        font-size: 16px;
        font-weight: bold;
        border: none;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    .metric-container {
        background-color: #1E2130;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
    }
    .report-container {
        background-color: #1E2130;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
    }
    </style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆåœ¨å…¨å±€ä½œç”¨åŸŸä¸­å®šä¹‰ï¼Œé¿å…é‡å¤åˆå§‹åŒ–ï¼‰
if 'current_analysis' not in st.session_state:
    st.session_state.current_analysis = "å¸‚åœºè¡Œä¸ºåˆ†æ"
if 'symbol' not in st.session_state:
    st.session_state.symbol = "BTCUSDT"
if 'timestamps' not in st.session_state:
    st.session_state.timestamps = []
    st.session_state.spot_prices = []
    st.session_state.futures_prices = []
    st.session_state.premiums = []
    st.session_state.funding_rates = []
    st.session_state.open_interest = []
    st.session_state.last_funding_rate = None
    st.session_state.running = False
    st.session_state.charts = [None, None, None]
    st.session_state.historical_data_loaded = False
    st.session_state.stats_data = None
    st.session_state.last_stats_update = None


class RateLimiter:
    """è¯·æ±‚é¢‘ç‡é™åˆ¶å™¨"""

    def __init__(self, max_requests, time_window):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = []
        self.lock = threading.Lock()

    def acquire(self):
        with self.lock:
            now = time.time()
            self.requests = [req for req in self.requests if now - req < self.time_window]
            if len(self.requests) >= self.max_requests:
                sleep_time = self.requests[0] + self.time_window - now
                if sleep_time > 0:
                    time.sleep(sleep_time)
            self.requests.append(now)


def fetch_data(url: str, params: dict = None, retries: int = 3) -> dict:
    """é€šç”¨æ•°æ®è·å–å‡½æ•°ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(retries):
        try:
            response = requests.get(url, params=params, timeout=10)  # è®¾ç½®10ç§’è¶…æ—¶
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logger.error(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {e}")
            if attempt < retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"è¯·æ±‚æœ€ç»ˆå¤±è´¥: {url}")
                return None


def calculate_rsi(prices: pd.Series, periods: int = 14) -> pd.Series:
    """è®¡ç®—RSIæŒ‡æ ‡"""
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=periods).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=periods).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))


def calculate_support_resistance(df: pd.DataFrame, window: int = 20) -> tuple:
    """è®¡ç®—æ”¯æ’‘å’Œé˜»åŠ›ä½"""
    rolling_low = df['low'].rolling(window=window).min()
    rolling_high = df['high'].rolling(window=window).max()
    support = rolling_low.iloc[-1]
    resistance = rolling_high.iloc[-1]
    return support, resistance


def get_binance_klines(symbol: str, interval: str, limit: int = 100) -> pd.DataFrame:
    """è·å–å¸å®‰Kçº¿æ•°æ®"""
    url = f"{BINANCE_API_URL}/api/v3/klines"  # ä½¿ç”¨ /api/v3/klines ç«¯ç‚¹
    params = {
        "symbol": symbol,
        "interval": interval,
        "limit": limit
    }
    try:
        data = fetch_data(url, params)
        if not data or not isinstance(data, list):
            logger.error(f"è·å–Kçº¿æ•°æ®å¤±è´¥: æ— æ•ˆå“åº”æ•°æ® - {symbol}, {interval}")
            return pd.DataFrame()

        df = pd.DataFrame(data, columns=[
            'open_time', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades', 'taker_buy_volume',
            'taker_buy_quote_volume', 'ignore'
        ])

        required_columns = ['open', 'high', 'low', 'close', 'volume']
        if not all(col in df.columns for col in required_columns):
            logger.error(f"Kçº¿æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {df.columns.tolist()}")
            return pd.DataFrame()

        df[required_columns] = df[required_columns].astype(float)
        df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
        return df
    except Exception as e:
        logger.error(f"å¤„ç†Kçº¿æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return pd.DataFrame()


class BinanceFuturesAnalyzer:
    """å¸å®‰æœŸè´§åˆ†æå™¨"""

    def __init__(self):
        self.base_url = "https://fapi.binance.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.rate_limiter = RateLimiter(max_requests=5, time_window=1.0)

    def get_usdt_symbols(self) -> List[str]:
        """è·å–æ‰€æœ‰USDTåˆçº¦äº¤æ˜“å¯¹"""
        url = f"{self.base_url}/fapi/v1/exchangeInfo"
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            data = response.json()
            return [symbol['symbol'] for symbol in data['symbols']
                    if symbol['symbol'].endswith('USDT') and symbol['status'] == 'TRADING']
        except Exception as e:
            logger.error(f"è·å–äº¤æ˜“å¯¹å¤±è´¥: {e}")
            return []

    def get_open_interest(self, symbol: str, period: str = "5m") -> Dict:
        """è·å–å•ä¸ªäº¤æ˜“å¯¹çš„æŒä»“é‡æ•°æ®"""
        self.rate_limiter.acquire()
        url = f"{self.base_url}/futures/data/openInterestHist"
        params = {
            "symbol": symbol,
            "period": period,
            "limit": 500
        }
        try:
            response = requests.get(url, params=params, headers=self.headers)
            response.raise_for_status()
            data = response.json()
            return {"symbol": symbol, "data": data}
        except Exception as e:
            logger.error(f"è·å–{symbol}æŒä»“æ•°æ®å¤±è´¥: {e}")
            return None

    def analyze_positions(self) -> pd.DataFrame:
        """åˆ†ææ‰€æœ‰äº¤æ˜“å¯¹çš„æŒä»“æƒ…å†µ"""
        symbols = self.get_usdt_symbols()
        historical_data = {}
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_symbol = {
                executor.submit(self.get_open_interest, symbol): symbol
                for symbol in symbols
            }
            for future in future_to_symbol:
                symbol = future_to_symbol[future]
                try:
                    result = future.result()
                    if result and result['data']:
                        historical_data[symbol] = result['data']
                except Exception as e:
                    logger.error(f"å¤„ç†{symbol}æ•°æ®å¤±è´¥: {e}")

        analysis_results = []
        for symbol, data in historical_data.items():
            if not data:
                continue
            df = pd.DataFrame(data)
            try:
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                df['sumOpenInterest'] = df['sumOpenInterest'].astype(float)
            except Exception as e:
                logger.error(f"æ•°æ®å¤„ç†å¤±è´¥: {e}")
                continue

            current_oi = float(df['sumOpenInterest'].iloc[-1])
            changes = {}
            for period, hours in [('1å°æ—¶', 1), ('4å°æ—¶', 4), ('24å°æ—¶', 24)]:
                try:
                    past_oi = float(df[df['timestamp'] <=
                                       df['timestamp'].max() - pd.Timedelta(hours=hours)]
                                    ['sumOpenInterest'].iloc[-1])
                    change = current_oi - past_oi
                    change_percentage = (change / past_oi) * 100
                    changes[period] = {'change': change, 'change_percentage': change_percentage}
                except (IndexError, ValueError):
                    changes[period] = {'change': 0, 'change_percentage': 0}

            try:
                percentile = (df['sumOpenInterest'].rank(pct=True).iloc[-1]) * 100
            except Exception:
                percentile = 0

            analysis_results.append({
                'symbol': symbol,
                'current_oi': current_oi,
                'percentile': percentile,
                'changes': changes
            })

        df = pd.DataFrame(analysis_results)
        if 'changes' in df.columns:
            df['change_percentage'] = df['changes'].apply(
                lambda x: x.get('24å°æ—¶', {}).get('change_percentage', 0)
            )
        else:
            df['change_percentage'] = 0
        return df

    def analyze_market_behavior(self, symbol: str, position_data: dict) -> str:
        """åˆ†æå¸‚åœºè¡Œä¸ºå¹¶ç”ŸæˆAIæŠ¥å‘Š"""
        price_data = {}
        for period, hours in [('1h', 1), ('4h', 4), ('1d', 24)]:
            df = get_binance_klines(symbol, period, limit=2)
            if not df.empty:
                price_change = ((float(df['close'].iloc[-1]) - float(df['open'].iloc[0]))
                                / float(df['open'].iloc[0])) * 100
                price_data[f'{hours}h_change'] = price_change

        daily_klines = get_binance_klines(symbol, '1d', limit=1)
        volatility = 0
        if not daily_klines.empty:
            high = float(daily_klines['high'].iloc[0])
            low = float(daily_klines['low'].iloc[0])
            volatility = ((high - low) / low) * 100

        prompt = (
            f"åŸºäº{symbol}æœŸè´§å¸‚åœºçš„ä»¥ä¸‹å…³é”®æ•°æ®è¿›è¡Œä¸“ä¸šå¸‚åœºè¡Œä¸ºåˆ†æï¼š\n\n"
            f"**å¸‚åœºçŠ¶æ€æŒ‡æ ‡**\n"
            f"- å½“å‰æŒä»“é‡ï¼š{position_data['current_oi']:,.0f}\n"
            f"- æŒä»“åˆ†ä½æ•°ï¼š{position_data['percentile']:.2f}%ï¼ˆé«˜ä½>80%ï¼Œä½ä½<20%ï¼‰\n"
            f"- 24å°æ—¶æ³¢åŠ¨ç‡ï¼š{volatility:.2f}%\n\n"
            f"**å¤šå‘¨æœŸä»·æ ¼ä¸æŒä»“å¯¹æ¯”**\n"
            f"| å‘¨æœŸ | ä»·æ ¼å˜åŒ– | æŒä»“å˜åŒ– |\n"
            f"|------|----------|----------|\n"
            f"| 1å°æ—¶ | {price_data.get('1h_change', 0):.2f}% | {position_data['changes']['1å°æ—¶']['change_percentage']:.2f}% |\n"
            f"| 4å°æ—¶ | {price_data.get('4h_change', 0):.2f}% | {position_data['changes']['4å°æ—¶']['change_percentage']:.2f}% |\n"
            f"| 24å°æ—¶ | {price_data.get('24h_change', 0):.2f}% | {position_data['changes']['24å°æ—¶']['change_percentage']:.2f}% |\n\n"

            f"è¯·æä¾›ä¸“ä¸šçš„å¸‚åœºè¡Œä¸ºåˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†ï¼š\n"
            f"1. **å¸‚åœºè¡Œä¸ºæ¨¡å¼è¯†åˆ«**ï¼šåŸºäºä»·æ ¼ä¸æŒä»“é‡å˜åŒ–å…³ç³»è¯†åˆ«å½“å‰å¸‚åœºè¡Œä¸ºæ¨¡å¼\n"
            f"2. **å¤šç©ºåŠ›é‡å¯¹æ¯”**ï¼šç¡®å®šå½“å‰ä¸»å¯¼æ–¹å‘åŠå…¶å¼ºåº¦\n"
            f"3. **äº¤æ˜“ç­–ç•¥å»ºè®®**ï¼šæä¾›å…·ä½“çš„æ“ä½œæ€è·¯å’Œå…³é”®ä»·æ ¼æ°´å¹³\n\n"

            f"è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼Œç»“æ„æ¸…æ™°ï¼Œè¯­è¨€ç®€æ´ä¸“ä¸šï¼Œçªå‡ºå¯æ“ä½œä¿¡å·ï¼Œé¿å…å†—ä½™æè¿°ã€‚"
            f"ä½¿ç”¨è¡¨æ ¼å¯¹æ¯”æ•°æ®ï¼Œå…³é”®æŒ‡æ ‡ç”¨**ç²—ä½“**æ ‡æ³¨ï¼Œæ˜ç¡®æ ‡ç¤ºæ“ä½œå»ºè®®çš„ç½®ä¿¡åº¦ã€‚"
        )
        try:
            response = client.chat.completions.create(
                model="deepseek-reasoner",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=4000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ç”ŸæˆAIåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            return "AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    def generate_position_report(self, df: pd.DataFrame) -> str:
        """ç”ŸæˆæŒä»“åˆ†æAIæŠ¥å‘Š"""
        df['change_percentage'] = df.apply(lambda x: x['changes']['24å°æ—¶']['change_percentage'], axis=1)
        top_increase = df.nlargest(10, 'change_percentage')
        top_decrease = df.nsmallest(10, 'change_percentage')

        prompt = (
            f"åŸºäºBinanceæœŸè´§å¸‚åœºUSDTäº¤æ˜“å¯¹çš„æŒä»“é‡å˜åŒ–æ•°æ®è¿›è¡Œä¸“ä¸šå¸‚åœºåˆ†æï¼š\n\n"
            f"**æŒä»“å¢åŠ æœ€æ˜¾è‘—çš„å‰10ä¸ªäº¤æ˜“å¯¹**\n"
            f"```\n{top_increase[['symbol', 'change_percentage']].to_string()}\n```\n\n"
            f"**æŒä»“å‡å°‘æœ€æ˜¾è‘—çš„å‰10ä¸ªäº¤æ˜“å¯¹**\n"
            f"```\n{top_decrease[['symbol', 'change_percentage']].to_string()}\n```\n\n"

            f"è¯·æä¾›ä¸“ä¸šçš„æŒä»“åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†ï¼š\n"
            f"1. **å¸‚åœºæƒ…ç»ªåˆ†æ**ï¼šåŸºäºæŒä»“å˜åŒ–è¯„ä¼°æ•´ä½“å¸‚åœºæƒ…ç»ª\n"
            f"2. **èµ„é‡‘æµå‘è§£è¯»**ï¼šåˆ†æä¸»è¦èµ„é‡‘æµå…¥/æµå‡ºçš„å¸ç§ç±»åˆ«\n"
            f"3. **äº¤æ˜“ç­–ç•¥å»ºè®®**ï¼šæä¾›é‡ç‚¹å…³æ³¨å¸ç§åŠå…¶é€‰æ‹©ç†ç”±\n\n"

            f"è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼Œç»“æ„ä¸ºï¼š[å¸‚åœºæƒ…ç»ªåˆ†æ]â†’[èµ„é‡‘æµå‘è§£è¯»]â†’[äº¤æ˜“ç­–ç•¥å»ºè®®]ã€‚"
            f"è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œçªå‡ºå¯æ“ä½œä¿¡å·ï¼Œé¿å…å†—ä½™æè¿°ã€‚"
            f"ä½¿ç”¨è¡¨æ ¼å¯¹æ¯”ä¸åŒå¸ç§ç±»åˆ«çš„èµ„é‡‘æµå‘ç‰¹å¾ï¼Œå…³é”®æŒ‡æ ‡ç”¨**ç²—ä½“**æ ‡æ³¨ã€‚"
        )
        try:
            response = client.chat.completions.create(
                model="deepseek-reasoner",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=4000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ç”ŸæˆæŒä»“åˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            return "AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

def multi_timeframe_analysis(symbol: str) -> dict:
    """å¤šå‘¨æœŸåˆ†æåŠŸèƒ½"""
    results = {}
    trends = {}
    for tf, info in TIMEFRAMES.items():
        df = get_binance_klines(symbol, info['interval'], limit=100)
        if df.empty:
            logger.warning(f"æ—¶é—´å‘¨æœŸ {tf} æ•°æ®è·å–å¤±è´¥")
            continue

        df['rsi'] = calculate_rsi(df['close'])
        support, resistance = calculate_support_resistance(df)
        sma20 = df['close'].rolling(window=20).mean()
        sma50 = df['close'].rolling(window=50).mean()
        current_price = float(df['close'].iloc[-1])

        if current_price > sma20.iloc[-1] > sma50.iloc[-1]:
            trend = "ä¸Šå‡"
        elif current_price < sma20.iloc[-1] < sma50.iloc[-1]:
            trend = "ä¸‹é™"
        else:
            trend = "éœ‡è¡"

        volume_sma = df['volume'].rolling(window=20).mean()
        volume_trend = "æ”¾é‡" if df['volume'].iloc[-1] > volume_sma.iloc[-1] else "ç¼©é‡"

        trends[tf] = {
            "trend": trend,
            "rsi": df['rsi'].iloc[-1],
            "support": support,
            "resistance": resistance,
            "volume_trend": volume_trend
        }

    if not trends:
        return {"error": "æ— æ³•è·å–ä»»ä½•æ—¶é—´å‘¨æœŸçš„æ•°æ®"}

    df_current = get_binance_klines(symbol, '1m', limit=1)
    if df_current.empty or 'close' not in df_current.columns:
        logger.error(f"è·å–å½“å‰ä»·æ ¼å¤±è´¥: æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘'close'åˆ—")
        return {"error": "æ— æ³•è·å–å½“å‰ä»·æ ¼æ•°æ®"}
    current_price = float(df_current['close'].iloc[0])

    short_term_trend = trends.get('5m', {}).get('trend', '') + "/" + trends.get('15m', {}).get('trend', '')
    medium_term_trend = trends.get('1h', {}).get('trend', '') + "/" + trends.get('4h', {}).get('trend', '')
    rsi_values = [data['rsi'] for data in trends.values()]
    avg_rsi = sum(rsi_values) / len(rsi_values) if rsi_values else 0

    risk = {"level": "ä¸­ç­‰", "factors": []}
    if avg_rsi > 70:
        risk["factors"].append("RSIè¶…ä¹°")
    elif avg_rsi < 30:
        risk["factors"].append("RSIè¶…å–")

    for tf, data in trends.items():
        if abs(current_price - data['resistance']) / current_price < 0.02:
            risk["factors"].append(f"{TIMEFRAMES[tf]['name']}æ¥è¿‘é˜»åŠ›ä½")
        if abs(current_price - data['support']) / current_price < 0.02:
            risk["factors"].append(f"{TIMEFRAMES[tf]['name']}æ¥è¿‘æ”¯æ’‘ä½")

    risk["level"] = "é«˜" if len(risk["factors"]) >= 3 else "ä½" if len(risk["factors"]) <= 1 else "ä¸­ç­‰"

    # åˆ›å»ºè¶‹åŠ¿è¡¨æ ¼æ•°æ®
    trend_table_data = []
    for tf in ['5m', '15m', '1h', '4h', '1d']:
        if tf in trends:
            trend_table_data.append({
                "å‘¨æœŸ": TIMEFRAMES[tf]['name'],
                "è¶‹åŠ¿": trends[tf]['trend'],
                "RSI": f"{trends[tf]['rsi']:.2f}",
                "æ”¯æ’‘ä½": f"{trends[tf]['support']:.2f}",
                "é˜»åŠ›ä½": f"{trends[tf]['resistance']:.2f}",
                "æˆäº¤é‡": trends[tf]['volume_trend']
            })

    # æ„å»ºæ›´ç»“æ„åŒ–çš„æç¤º
    prompt = (
        f"è¯·ç”Ÿæˆä¸€ä»½å…³äº{symbol}çš„å¤šå‘¨æœŸæŠ€æœ¯åˆ†ææŠ¥å‘Šï¼Œæ ¼å¼å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„ï¼š\n\n"

        f"## å¸‚åœºç»“æ„\n"
        f"å½“å‰å¸‚åœºå‘ˆç° **[ä¸»è¦ç‰¹å¾æè¿°]** ç‰¹å¾ï¼š\n"
        f"- **çŸ­æœŸåŠ¨èƒ½**ï¼š[5åˆ†é’Ÿå’Œ15åˆ†é’Ÿå‘¨æœŸåˆ†æ]\n"
        f"- **ä¸­æœŸèµ°åŠ¿**ï¼š[1å°æ—¶å’Œ4å°æ—¶å‘¨æœŸåˆ†æ]\n"
        f"- **é•¿æœŸè¶‹åŠ¿**ï¼š[æ—¥çº¿å‘¨æœŸåˆ†æ]\n\n"
        f"å¸‚åœºç»“æ„å¤„äº **[ç»“æ„å®šä½]** é˜¶æ®µï¼Œ[é¢å¤–å¸‚åœºç‰¹å¾æè¿°]\n\n"

        f"## æŠ€æœ¯é¢åˆ†æ\n"
        f"### å…³é”®æŒ‡æ ‡äº¤äº’éªŒè¯\n"
        f"1. **ä»·æ ¼ç»“æ„**ï¼š\n"
        f"   - [æ”¯æ’‘ä½åˆ†æ]\n"
        f"   - [é˜»åŠ›ä½åˆ†æ]\n\n"
        f"2. **åŠ¨é‡æŒ‡æ ‡**ï¼š\n"
        f"   - [RSIåˆ†æ]\n"
        f"   - [å…¶ä»–åŠ¨é‡æŒ‡æ ‡åˆ†æ]\n\n"
        f"3. **é‡ä»·é…åˆ**ï¼š\n"
        f"   - [æˆäº¤é‡ä¸ä»·æ ¼å…³ç³»åˆ†æ]\n"
        f"   - [æˆäº¤é‡è¶‹åŠ¿åˆ†æ]\n\n"

        f"## æ“ä½œå»ºè®®\n"
        f"### çŸ­æœŸç­–ç•¥ï¼ˆæ—¥å†…äº¤æ˜“ï¼‰\n"
        f"**å¤šå¤´ç­–ç•¥**ï¼š\n"
        f"- å…¥åœºï¼š[å…¥åœºç‚¹ä½å’Œæ¡ä»¶]\n"
        f"- ç›®æ ‡ï¼š[ç›®æ ‡ä»·ä½]\n"
        f"- æ­¢æŸï¼š[æ­¢æŸä»·ä½]\n\n"
        f"**ç©ºå¤´ç­–ç•¥**ï¼š\n"
        f"- è§¦å‘æ¡ä»¶ï¼š[è§¦å‘æ¡ä»¶]\n"
        f"- ç›®æ ‡ï¼š[ç›®æ ‡ä»·ä½]\n"
        f"- æ­¢æŸï¼š[æ­¢æŸä»·ä½]\n\n"
    )

    # æ·»åŠ æ•°æ®ä¿¡æ¯
    data_info = (
        f"åŸºäºä»¥ä¸‹æ•°æ®è¿›è¡Œåˆ†æï¼š\n"
        f"- å½“å‰ä»·æ ¼ï¼š{current_price:.2f}\n"
        f"- çŸ­æœŸè¶‹åŠ¿ï¼ˆ5m/15mï¼‰ï¼š{short_term_trend}\n"
        f"- ä¸­æœŸè¶‹åŠ¿ï¼ˆ1h/4hï¼‰ï¼š{medium_term_trend}\n"
        f"- RSIæŒ‡æ ‡ï¼š{avg_rsi:.2f}\n"
        f"- æ”¯æ’‘ä½ï¼š{trends.get('1h', {}).get('support', 'N/A'):.2f}\n"
        f"- é˜»åŠ›ä½ï¼š{trends.get('1h', {}).get('resistance', 'N/A'):.2f}\n"
        f"- é£é™©ç­‰çº§ï¼š{risk['level']}\n"
        f"- é£é™©å› ç´ ï¼š{', '.join(risk['factors']) if risk['factors'] else 'æ— é‡å¤§é£é™©'}\n"
    )

    try:
        response = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {"role": "system",
                 "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŠ å¯†è´§å¸æŠ€æœ¯åˆ†æå¸ˆï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ ¼å¼ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„ç« èŠ‚æˆ–æ ‡é¢˜ã€‚"},
                {"role": "user", "content": prompt + data_info}
            ],
            temperature=0.5,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„è¾“å‡º
            max_tokens=4000
        )
        ai_analysis = response.choices[0].message.content

        # ç¡®ä¿æ ¼å¼ä¸€è‡´æ€§
        if not ai_analysis.startswith(f"# {symbol} æŠ€æœ¯åˆ†ææŠ¥å‘Š"):
            ai_analysis = f"# {symbol} æŠ€æœ¯åˆ†ææŠ¥å‘Š\n\n" + ai_analysis

        # ç¡®ä¿ä¸»è¦éƒ¨åˆ†å­˜åœ¨
        required_sections = ["## å¸‚åœºç»“æ„", "## æŠ€æœ¯é¢åˆ†æ", "## æ“ä½œå»ºè®®"]
        for section in required_sections:
            if section not in ai_analysis:
                ai_analysis = ai_analysis.replace(section.replace("##", "#"), section)
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤šå‘¨æœŸåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
        ai_analysis = "AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    return {
        "current_price": current_price,
        "trends": trends,
        "risk": risk,
        "ai_analysis": ai_analysis
    }


class FundFlowAnalyzer:
    """èµ„é‡‘æµå‘åˆ†æå™¨"""

    def __init__(self):
        self.spot_base_url = "https://api.binance.com/api/v3"
        self.futures_base_url = "https://fapi.binance.com/fapi/v1"
        self.stablecoins = {'USDC', 'TUSD', 'BUSD', 'DAI', 'USDP', 'EUR', 'GYEN'}

    def get_all_usdt_symbols(self, is_futures=False):
        """è·å–æ‰€æœ‰ä»¥USDTç»“å°¾çš„äº¤æ˜“å¯¹ï¼Œå‰”é™¤ç¨³å®šå¸å¯¹"""
        base_url = self.futures_base_url if is_futures else self.spot_base_url
        endpoint = "/exchangeInfo"
        response = requests.get(f"{base_url}{endpoint}")
        data = response.json()
        symbols = []
        if is_futures:
            for item in data['symbols']:
                symbol = item['symbol']
                base_asset = item['baseAsset']
                if (item['status'] == 'TRADING' and
                        item['quoteAsset'] == 'USDT' and
                        base_asset not in self.stablecoins):
                    symbols.append(symbol)
        else:
            for item in data['symbols']:
                symbol = item['symbol']
                base_asset = item['baseAsset']
                if (item['status'] == 'TRADING' and
                        item['quoteAsset'] == 'USDT' and
                        base_asset not in self.stablecoins):
                    symbols.append(symbol)
        return symbols

    def format_number(self, value):
        """å°†æ•°å€¼æ ¼å¼åŒ–ä¸ºK/Mè¡¨ç¤ºï¼Œä¿ç•™ä¸¤ä½å°æ•°"""
        if abs(value) >= 1000000:
            return f"{value / 1000000:.2f}M"
        elif abs(value) >= 1000:
            return f"{value / 1000:.2f}K"
        else:
            return f"{value:.2f}"

    def get_klines_parallel(self, symbols, is_futures=False, max_workers=20, include_latest=False):
        """ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè·å–å¤šä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®ï¼ˆåŸºäºæœ€è¿‘å®Œæˆçš„ 4H Kçº¿ï¼Œå¯é€‰æœ€æ–°ä»·æ ¼ï¼‰"""
        results = []
        failed_symbols = []

        def fetch_kline(symbol):
            try:
                base_url = self.futures_base_url if is_futures else self.spot_base_url
                endpoint = "/klines"
                now = datetime.utcnow()
                # è®¡ç®—æœ€è¿‘å®Œæˆçš„ 4H å‘¨æœŸ
                hours_since_day_start = now.hour + now.minute / 60 + now.second / 3600
                last_4h_offset = int(hours_since_day_start // 4) * 4
                last_4h_start = now.replace(minute=0, second=0, microsecond=0, hour=0) + timedelta(hours=last_4h_offset)
                if last_4h_start > now:
                    last_4h_start -= timedelta(hours=4)
                end_time = int(last_4h_start.timestamp() * 1000)
                start_time = int((last_4h_start - timedelta(hours=4)).timestamp() * 1000)
                params = {
                    'symbol': symbol,
                    'interval': '4h',
                    'startTime': start_time,
                    'endTime': end_time,
                    'limit': 2
                }
                response = requests.get(f"{base_url}{endpoint}", params=params)
                response.raise_for_status()
                data = response.json()
                if not data or len(data) < 2:
                    logger.error(f"æ•°æ®ä¸è¶³ {symbol}: è¿”å› {len(data)} æ ¹Kçº¿")
                    return None
                k = data[-1]
                result = {
                    'symbol': symbol,
                    'open_time': datetime.fromtimestamp(k[0] / 1000).strftime('%Y-%m-%d %H:%M:%S'),
                    'close_time': datetime.fromtimestamp(k[6] / 1000).strftime('%Y-%m-%d %H:%M:%S'),
                    'open': float(k[1]),
                    'high': float(k[2]),
                    'low': float(k[3]),
                    'close': float(k[4]),
                    'volume': float(k[5]),
                    'quote_volume': float(k[7]),
                    'trades': int(k[8]),
                    'taker_buy_base_volume': float(k[9]),
                    'taker_buy_quote_volume': float(k[10]),
                    'net_inflow': 2 * float(k[10]) - float(k[7])
                }
                # è·å–æœ€æ–°ä»·æ ¼ï¼ˆå¯é€‰ï¼‰
                if include_latest:
                    latest_params = {
                        'symbol': symbol,
                        'interval': '1m',
                        'limit': 1
                    }
                    latest_response = requests.get(f"{base_url}{endpoint}", params=latest_params)
                    latest_response.raise_for_status()
                    latest_data = latest_response.json()
                    if latest_data and len(latest_data) > 0:
                        result['latest_price'] = float(latest_data[0][4])  # æœ€æ–°æ”¶ç›˜ä»·
                    else:
                        result['latest_price'] = result['close']  # å›é€€åˆ° 4H æ”¶ç›˜ä»·
                return result
            except Exception as e:
                logger.error(f"è·å– {symbol} æ•°æ®å‡ºé”™: {e}")
                return None
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(fetch_kline, symbol): symbol for symbol in symbols}
            for future in concurrent.futures.as_completed(futures):
                symbol = futures[future]
                result = future.result()
                if result:
                    results.append(result)
                else:
                    failed_symbols.append(symbol)
        if failed_symbols:
            logger.warning(f"ä»¥ä¸‹äº¤æ˜“å¯¹æ•°æ®è·å–å¤±è´¥: {failed_symbols}")
        if not results:
            logger.error("æ‰€æœ‰äº¤æ˜“å¯¹æ•°æ®è·å–å¤±è´¥")
            return []
        return results

    def send_to_deepseek(self, data):
        """å‘é€æ•°æ®åˆ° DeepSeek API ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        prompt = (
            "åŸºäºBinanceç°è´§å’ŒæœŸè´§å¸‚åœºUSDTäº¤æ˜“å¯¹å‰4Hå·²å®Œæˆæ”¶ç›˜æ•°æ®çš„èµ„é‡‘æµå…¥æµå‡ºæƒ…å†µï¼Œç”Ÿæˆä¸“ä¸šèµ„é‡‘æµå‘åˆ†ææŠ¥å‘Šã€‚æ•°æ®å¦‚ä¸‹ï¼š\n" +
            json.dumps(data, indent=2, ensure_ascii=False) +
            "\n\n"
            "### åˆ†æè¦æ±‚\n"
            "1. **ä¸»åŠ›èµ„é‡‘è¡Œä¸ºè§£è¯»**ï¼š\n"
            "   - è¯†åˆ«ç°è´§å’ŒæœŸè´§å¸‚åœºä¸­ç›¸åŒäº¤æ˜“å¯¹çš„èµ„é‡‘æµå‘ç‰¹å¾ï¼ˆå‡€æµå…¥/æµå‡ºï¼‰ã€‚\n"
            "   - åˆ†ææ½œåœ¨ä¸»åŠ›è¡Œä¸ºï¼ˆå¦‚å¸ç­¹ã€æ‹‰æŠ¬ã€å¯¹å†²ã€å¯¹å€’ï¼‰ï¼Œç»“åˆé‡ä»·å…³ç³»ï¼ˆé«˜æˆäº¤é‡ä½æ³¢åŠ¨ç­‰ï¼‰ã€‚\n"
            "   - è¯„ä¼°è®¢å•ç°¿å‹åŠ›ï¼ˆvolume imbalanceï¼‰å’Œèµ„é‡‘æµå‘ä¸ä»·æ ¼çš„ç›¸å…³æ€§ã€‚\n"
            "2. **ä»·æ ¼é˜¶æ®µåˆ¤æ–­**ï¼š\n"
            "   - æ ¹æ®èµ„é‡‘æµå‘æ¨æ–­å¸‚åœºé˜¶æ®µï¼ˆæ•´ç†/ä¸Šæ¶¨/ä¸‹è·Œï¼‰ï¼Œé‡åŒ–ç½®ä¿¡åº¦ï¼ˆå¦‚ç›¸å…³æ€§æˆ–è¶‹åŠ¿å¼ºåº¦ï¼‰ã€‚\n"
            "   - å¯¹æ¯”ç°è´§å’ŒæœŸè´§å¸‚åœºçš„è¶‹åŠ¿ä¸€è‡´æ€§åŠä¸»å¯¼å…³ç³»ã€‚\n"
            "3. **çŸ­æœŸè¶‹åŠ¿é¢„åˆ¤ï¼ˆ4-8å°æ—¶ï¼‰**ï¼š\n"
            "   - é¢„æµ‹ä¸»è¦äº¤æ˜“å¯¹çš„çŸ­æœŸæ–¹å‘ï¼ˆçœ‹æ¶¨/çœ‹è·Œ/éœ‡è¡ï¼‰ï¼Œæ ‡ç¤ºå…³é”®æ”¯æ’‘/é˜»åŠ›ä½ã€‚\n"
            "4. **äº¤æ˜“ç­–ç•¥å»ºè®®**ï¼š\n"
            "   - é’ˆå¯¹ä¸»è¦äº¤æ˜“å¯¹ï¼ˆå¦‚BTCUSDTã€ETHUSDTï¼‰æå‡ºå…·ä½“æ“ä½œç­–ç•¥ï¼ˆæ–¹å‘ã€å…¥åœºç‚¹ã€æ­¢æŸã€ç›®æ ‡ï¼‰ã€‚\n"
            "   - æä¾›é£é™©æ”¶ç›Šæ¯”å’Œå¯¹å†²å»ºè®®ã€‚\n"
            "\n"
            "### è¾“å‡ºè§„èŒƒ\n"
            "- ä½¿ç”¨Markdownæ ¼å¼ï¼Œç»“æ„ä¸ºï¼š[ä¸»åŠ›èµ„é‡‘è¡Œä¸ºè§£è¯»]â†’[ä»·æ ¼é˜¶æ®µåˆ¤æ–­]â†’[çŸ­æœŸè¶‹åŠ¿é¢„åˆ¤]â†’[äº¤æ˜“ç­–ç•¥å»ºè®®]ã€‚\n"
            "- è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œçªå‡ºå¯æ“ä½œä¿¡å·ï¼Œé¿å…å†—ä½™æè¿°ã€‚\n"
            "- æ•°æ®å‘ˆç°ï¼š\n"
            "  - å…³é”®æŒ‡æ ‡ï¼ˆå¦‚volume imbalanceã€correlationï¼‰ç”¨**ç²—ä½“**æ ‡æ³¨ã€‚\n"
            "  - è¡¨æ ¼å¯¹æ¯”ç°è´§/æœŸè´§èµ„é‡‘æµå‘åŠç­–ç•¥è¦ç‚¹ã€‚\n"
            "  - è¶‹åŠ¿ç½®ä¿¡åº¦ä»¥ç™¾åˆ†æ¯”æˆ–på€¼è¡¨è¿°ã€‚\n"
            "- ä»¥ä¸­æ–‡å›å¤ï¼Œç¡®ä¿é€»è¾‘æ¸…æ™°ï¼Œé€‚ç”¨äºäº¤æ˜“å†³ç­–ã€‚\n"
        )
        try:
            response = client.chat.completions.create(
                model="deepseek-reasoner",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=4000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"DeepSeek APIé”™è¯¯: {e}")
            return "æ— æ³•è·å–DeepSeekåˆ†æç»“æœ"

    def analyze_fund_flow(self):
        """åˆ†æèµ„é‡‘æµå‘"""
        spot_symbols = self.get_all_usdt_symbols(is_futures=False)
        futures_symbols = self.get_all_usdt_symbols(is_futures=True)
        spot_data = self.get_klines_parallel(spot_symbols, is_futures=False, max_workers=20, include_latest=True)
        futures_data = self.get_klines_parallel(futures_symbols, is_futures=True, max_workers=20, include_latest=True)
        spot_df = pd.DataFrame(spot_data)
        futures_df = pd.DataFrame(futures_data)
        if spot_df.empty or 'net_inflow' not in spot_df.columns:
            logger.error("ç°è´§æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘ 'net_inflow' åˆ—")
            spot_df = pd.DataFrame(columns=['symbol', 'net_inflow', 'quote_volume', 'latest_price'])
        if futures_df.empty or 'net_inflow' not in futures_df.columns:
            logger.error("æœŸè´§æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘ 'net_inflow' åˆ—")
            futures_df = pd.DataFrame(columns=['symbol', 'net_inflow', 'quote_volume', 'latest_price'])
        spot_inflow_top20 = spot_df.sort_values(by='net_inflow', ascending=False).head(20)
        futures_inflow_top20 = futures_df.sort_values(by='net_inflow', ascending=False).head(20)
        spot_outflow_top20 = spot_df.sort_values(by='net_inflow', ascending=True).head(20)
        futures_outflow_top20 = futures_df.sort_values(by='net_inflow', ascending=True).head(20)
        deepseek_data = {
            "spot_inflow_top20": spot_inflow_top20[['symbol', 'net_inflow', 'quote_volume', 'latest_price']].to_dict('records'),
            "futures_inflow_top20": futures_inflow_top20[['symbol', 'net_inflow', 'quote_volume', 'latest_price']].to_dict('records'),
            "spot_outflow_top20": spot_outflow_top20[['symbol', 'net_inflow', 'quote_volume', 'latest_price']].to_dict('records'),
            "futures_outflow_top20": futures_outflow_top20[['symbol', 'net_inflow', 'quote_volume', 'latest_price']].to_dict('records'),
            "timestamp": datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
        }
        analysis = self.send_to_deepseek(deepseek_data)
        return {
            "spot_inflow_top20": spot_inflow_top20,
            "futures_inflow_top20": futures_inflow_top20,
            "spot_outflow_top20": spot_outflow_top20,
            "futures_outflow_top20": futures_outflow_top20,
            "analysis": analysis
        }

def main():
    st.title("åˆ†æç³»ç»Ÿ")
    st.sidebar.header("åŠŸèƒ½å¯¼èˆª")

    # åˆå§‹åŒ–åˆ†æé€‰æ‹©
    if st.sidebar.button("å¸‚åœºè¡Œä¸ºåˆ†æ",
                         type="primary" if st.session_state.current_analysis == "å¸‚åœºè¡Œä¸ºåˆ†æ" else "secondary",
                         use_container_width=True):
        st.session_state.current_analysis = "å¸‚åœºè¡Œä¸ºåˆ†æ"
    if st.sidebar.button("æŒä»“åˆ†æ",
                         type="primary" if st.session_state.current_analysis == "æŒä»“åˆ†æ" else "secondary",
                         use_container_width=True):
        st.session_state.current_analysis = "æŒä»“åˆ†æ"
    if st.sidebar.button("å¤šå‘¨æœŸåˆ†æ",
                         type="primary" if st.session_state.current_analysis == "å¤šå‘¨æœŸåˆ†æ" else "secondary",
                         use_container_width=True):
        st.session_state.current_analysis = "å¤šå‘¨æœŸåˆ†æ"
    if st.sidebar.button("èµ„é‡‘æµå‘åˆ†æ",
                         type="primary" if st.session_state.current_analysis == "èµ„é‡‘æµå‘åˆ†æ" else "secondary",
                         use_container_width=True):
        st.session_state.current_analysis = "èµ„é‡‘æµå‘åˆ†æ"

    # å¸‚åœºè¡Œä¸ºåˆ†æ
    if st.session_state.current_analysis == "å¸‚åœºè¡Œä¸ºåˆ†æ":
        st.header("å¸‚åœºè¡Œä¸ºåˆ†æ")
        analyzer = BinanceFuturesAnalyzer()
        symbols = analyzer.get_usdt_symbols()
        selected_symbol = st.selectbox("é€‰æ‹©äº¤æ˜“å¯¹", symbols)
        if st.button("å¼€å§‹åˆ†æ"):
            with st.spinner("æ­£åœ¨åˆ†æå¸‚åœºè¡Œä¸º..."):
                position_data = analyzer.get_open_interest(selected_symbol)
                if position_data and position_data['data']:
                    df = pd.DataFrame(position_data['data'])
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                    df['sumOpenInterest'] = df['sumOpenInterest'].astype(float)
                    current_oi = float(df['sumOpenInterest'].iloc[-1])
                    percentile = (df['sumOpenInterest'].rank(pct=True).iloc[-1]) * 100
                    changes = {}
                    for period, hours in [('1å°æ—¶', 1), ('4å°æ—¶', 4), ('24å°æ—¶', 24)]:
                        past_oi = float(df[df['timestamp'] <=
                                         df['timestamp'].max() - pd.Timedelta(hours=hours)]
                                      ['sumOpenInterest'].iloc[-1])
                        change = current_oi - past_oi
                        change_percentage = (change / past_oi) * 100
                        changes[period] = {'change': change, 'change_percentage': change_percentage}
                    position_info = {'current_oi': current_oi, 'percentile': percentile, 'changes': changes}
                    analysis_report = analyzer.analyze_market_behavior(selected_symbol, position_info)
                    st.markdown(analysis_report)

    # æŒä»“åˆ†æ
    elif st.session_state.current_analysis == "æŒä»“åˆ†æ":
        st.header("æŒä»“åˆ†æ")
        analyzer = BinanceFuturesAnalyzer()
        if st.button("åˆ†ææ‰€æœ‰äº¤æ˜“å¯¹æŒä»“"):
            with st.spinner("æ­£åœ¨åˆ†ææŒä»“æ•°æ®..."):
                df = analyzer.analyze_positions()
                st.subheader("æŒä»“å˜åŒ–Top10")
                increase_top10 = df.nlargest(10, 'change_percentage')[['symbol', 'change_percentage', 'current_oi']]
                decrease_top10 = df.nsmallest(10, 'change_percentage')[['symbol', 'change_percentage', 'current_oi']]
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**å¢æŒTop10**")
                    increase_display = increase_top10.copy()
                    increase_display.columns = ['äº¤æ˜“å¯¹', 'å˜åŒ–ç‡(%)', 'å½“å‰æŒä»“']
                    increase_display['å˜åŒ–ç‡(%)'] = increase_display['å˜åŒ–ç‡(%)'].round(2)
                    increase_display['å½“å‰æŒä»“'] = increase_display['å½“å‰æŒä»“'].round(2)
                    st.table(increase_display)
                with col2:
                    st.markdown("**å‡æŒTop10**")
                    decrease_display = decrease_top10.copy()
                    decrease_display.columns = ['äº¤æ˜“å¯¹', 'å˜åŒ–ç‡(%)', 'å½“å‰æŒä»“']
                    decrease_display['å˜åŒ–ç‡(%)'] = decrease_display['å˜åŒ–ç‡(%)'].round(2)
                    decrease_display['å½“å‰æŒä»“'] = decrease_display['å½“å‰æŒä»“'].round(2)
                    st.table(decrease_display)
                st.subheader("æ€»ä½“æŒä»“åˆ†æ")
                report = analyzer.generate_position_report(df)
                st.markdown(report)

    # å¤šå‘¨æœŸåˆ†æ
    elif st.session_state.current_analysis == "å¤šå‘¨æœŸåˆ†æ":
        st.header("å¤šå‘¨æœŸåˆ†æ")
        analyzer = BinanceFuturesAnalyzer()
        symbols = analyzer.get_usdt_symbols()
        selected_symbol = st.selectbox("é€‰æ‹©äº¤æ˜“å¯¹", symbols)
        if st.button("å¼€å§‹å¤šå‘¨æœŸåˆ†æ"):
            with st.spinner("æ­£åœ¨è¿›è¡Œå¤šå‘¨æœŸåˆ†æ..."):
                analysis_result = multi_timeframe_analysis(selected_symbol)
                if "error" in analysis_result:
                    st.error(analysis_result["error"])
                else:
                    st.markdown(analysis_result["ai_analysis"])

    # èµ„é‡‘æµå‘åˆ†æ
    elif st.session_state.current_analysis == "èµ„é‡‘æµå‘åˆ†æ":
        st.header("èµ„é‡‘æµå‘åˆ†æ")
        fund_flow_analyzer = FundFlowAnalyzer()
        if st.button("å¼€å§‹èµ„é‡‘æµå‘åˆ†æ"):
            with st.spinner("æ­£åœ¨åˆ†æèµ„é‡‘æµå‘..."):
                analysis_result = fund_flow_analyzer.analyze_fund_flow()
                st.subheader("ç°è´§äº¤æ˜“å¯¹å‡€æµå…¥TOP20")
                st.table(analysis_result["spot_inflow_top20"][['symbol', 'net_inflow', 'quote_volume']])
                st.subheader("æœŸè´§äº¤æ˜“å¯¹å‡€æµå…¥TOP20")
                st.table(analysis_result["futures_inflow_top20"][['symbol', 'net_inflow', 'quote_volume']])
                st.subheader("ç°è´§äº¤æ˜“å¯¹å‡€æµå‡ºTOP20")
                st.table(analysis_result["spot_outflow_top20"][['symbol', 'net_inflow', 'quote_volume']])
                st.subheader("æœŸè´§äº¤æ˜“å¯¹å‡€æµå‡ºTOP20")
                st.table(analysis_result["futures_outflow_top20"][['symbol', 'net_inflow', 'quote_volume']])
                st.subheader("DeepSeekåˆ†æç»“æœ")
                st.markdown(analysis_result["analysis"])

# è¿è¡Œä¸»ç¨‹åº
if __name__ == "__main__":
    main()

