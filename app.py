import streamlit as st
import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
import time
from openai import OpenAI
import logging
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
import threading
from typing import Dict, List, Any
import json
import concurrent.futures

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# APIé…ç½®
OPENAI_API_KEY = "xxxx" #æ›´æ–°ä¸ºè‡ªå·±çš„APIKey
BINANCE_API_URL = "https://api-gcp.binance.com"  # æ›´æ–°ä¸ºå®˜æ–¹æ¨èçš„ç°è´§APIç«¯ç‚¹
BINANCE_FUTURES_URL = "https://fapi.binance.com"

client = OpenAI(api_key=OPENAI_API_KEY, base_url="https://api.tu-zi.com/v1") #æ›´æ–°ä¸ºè‡ªå·±çš„APç½‘ç«™ï¼Œé»˜è®¤ä½¿ç”¨å…”å­API

# æ—¶é—´å‘¨æœŸé…ç½®
TIMEFRAMES = {
    "5m": {"interval": "5m", "name": "5åˆ†é’Ÿ", "weight": 0.1},
    "15m": {"interval": "15m", "name": "15åˆ†é’Ÿ", "weight": 0.15},
    "1h": {"interval": "1h", "name": "1å°æ—¶", "weight": 0.25},
    "4h": {"interval": "4h", "name": "4å°æ—¶", "weight": 0.25},
    "1d": {"interval": "1d", "name": "æ—¥çº¿", "weight": 0.25}
}

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .main {
        background-color: #0e1117;
    }
    div.stButton > button {
        width: 100%;
        background-color: #FF4B4B;
        color: white;
        border-radius: 10px;
        padding: 0.8rem 1rem;
        font-size: 16px;
        font-weight: bold;
        border: none;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    .metric-container {
        background-color: #1E2130;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
    }
    .report-container {
        background-color: #1E2130;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
    }
    </style>
""", unsafe_allow_html=True)

class RateLimiter:
    """è¯·æ±‚é¢‘ç‡é™åˆ¶å™¨"""
    def __init__(self, max_requests, time_window):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = []
        self.lock = threading.Lock()

    def acquire(self):
        with self.lock:
            now = time.time()
            self.requests = [req for req in self.requests if now - req < self.time_window]
            if len(self.requests) >= self.max_requests:
                sleep_time = self.requests[0] + self.time_window - now
                if sleep_time > 0:
                    time.sleep(sleep_time)
            self.requests.append(now)

def fetch_data(url: str, params: dict = None, retries: int = 3) -> dict:
    """é€šç”¨æ•°æ®è·å–å‡½æ•°ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(retries):
        try:
            response = requests.get(url, params=params, timeout=10)  # è®¾ç½®10ç§’è¶…æ—¶
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logger.error(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {e}")
            if attempt < retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"è¯·æ±‚æœ€ç»ˆå¤±è´¥: {url}")
                return None

def calculate_rsi(prices: pd.Series, periods: int = 14) -> pd.Series:
    """è®¡ç®—RSIæŒ‡æ ‡"""
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=periods).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=periods).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

def calculate_support_resistance(df: pd.DataFrame, window: int = 20) -> tuple:
    """è®¡ç®—æ”¯æ’‘å’Œé˜»åŠ›ä½"""
    rolling_low = df['low'].rolling(window=window).min()
    rolling_high = df['high'].rolling(window=window).max()
    support = rolling_low.iloc[-1]
    resistance = rolling_high.iloc[-1]
    return support, resistance

def get_binance_klines(symbol: str, interval: str, limit: int = 100) -> pd.DataFrame:
    """è·å–å¸å®‰Kçº¿æ•°æ®"""
    url = f"{BINANCE_API_URL}/api/v3/klines"  # ä½¿ç”¨ /api/v3/klines ç«¯ç‚¹
    params = {
        "symbol": symbol,
        "interval": interval,
        "limit": limit
    }
    try:
        data = fetch_data(url, params)
        if not data or not isinstance(data, list):
            logger.error(f"è·å–Kçº¿æ•°æ®å¤±è´¥: æ— æ•ˆå“åº”æ•°æ® - {symbol}, {interval}")
            return pd.DataFrame()

        df = pd.DataFrame(data, columns=[
            'open_time', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades', 'taker_buy_volume',
            'taker_buy_quote_volume', 'ignore'
        ])

        required_columns = ['open', 'high', 'low', 'close', 'volume']
        if not all(col in df.columns for col in required_columns):
            logger.error(f"Kçº¿æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {df.columns.tolist()}")
            return pd.DataFrame()

        df[required_columns] = df[required_columns].astype(float)
        df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
        return df
    except Exception as e:
        logger.error(f"å¤„ç†Kçº¿æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return pd.DataFrame()

class BinanceFuturesAnalyzer:
    """å¸å®‰æœŸè´§åˆ†æå™¨"""
    def __init__(self):
        self.base_url = "https://fapi.binance.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.rate_limiter = RateLimiter(max_requests=5, time_window=1.0)

    def get_usdt_symbols(self) -> List[str]:
        """è·å–æ‰€æœ‰USDTåˆçº¦äº¤æ˜“å¯¹"""
        url = f"{self.base_url}/fapi/v1/exchangeInfo"
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            data = response.json()
            return [symbol['symbol'] for symbol in data['symbols']
                    if symbol['symbol'].endswith('USDT') and symbol['status'] == 'TRADING']
        except Exception as e:
            logger.error(f"è·å–äº¤æ˜“å¯¹å¤±è´¥: {e}")
            return []

    def get_open_interest(self, symbol: str, period: str = "5m") -> Dict:
        """è·å–å•ä¸ªäº¤æ˜“å¯¹çš„æŒä»“é‡æ•°æ®"""
        self.rate_limiter.acquire()
        url = f"{self.base_url}/futures/data/openInterestHist"
        params = {
            "symbol": symbol,
            "period": period,
            "limit": 500
        }
        try:
            response = requests.get(url, params=params, headers=self.headers)
            response.raise_for_status()
            data = response.json()
            return {"symbol": symbol, "data": data}
        except Exception as e:
            logger.error(f"è·å–{symbol}æŒä»“æ•°æ®å¤±è´¥: {e}")
            return None

    def analyze_positions(self) -> pd.DataFrame:
        """åˆ†ææ‰€æœ‰äº¤æ˜“å¯¹çš„æŒä»“æƒ…å†µ"""
        symbols = self.get_usdt_symbols()
        historical_data = {}
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_symbol = {
                executor.submit(self.get_open_interest, symbol): symbol
                for symbol in symbols
            }
            for future in future_to_symbol:
                symbol = future_to_symbol[future]
                try:
                    result = future.result()
                    if result and result['data']:
                        historical_data[symbol] = result['data']
                except Exception as e:
                    logger.error(f"å¤„ç†{symbol}æ•°æ®å¤±è´¥: {e}")

        analysis_results = []
        for symbol, data in historical_data.items():
            if not data:
                continue
            df = pd.DataFrame(data)
            try:
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                df['sumOpenInterest'] = df['sumOpenInterest'].astype(float)
            except Exception as e:
                logger.error(f"æ•°æ®å¤„ç†å¤±è´¥: {e}")
                continue

            current_oi = float(df['sumOpenInterest'].iloc[-1])
            changes = {}
            for period, hours in [('1å°æ—¶', 1), ('4å°æ—¶', 4), ('24å°æ—¶', 24)]:
                try:
                    past_oi = float(df[df['timestamp'] <=
                                     df['timestamp'].max() - pd.Timedelta(hours=hours)]
                                  ['sumOpenInterest'].iloc[-1])
                    change = current_oi - past_oi
                    change_percentage = (change / past_oi) * 100
                    changes[period] = {'change': change, 'change_percentage': change_percentage}
                except (IndexError, ValueError):
                    changes[period] = {'change': 0, 'change_percentage': 0}

            try:
                percentile = (df['sumOpenInterest'].rank(pct=True).iloc[-1]) * 100
            except Exception:
                percentile = 0

            analysis_results.append({
                'symbol': symbol,
                'current_oi': current_oi,
                'percentile': percentile,
                'changes': changes
            })

        df = pd.DataFrame(analysis_results)
        if 'changes' in df.columns:
            df['change_percentage'] = df['changes'].apply(
                lambda x: x.get('24å°æ—¶', {}).get('change_percentage', 0)
            )
        else:
            df['change_percentage'] = 0
        return df

    def analyze_market_behavior(self, symbol: str, position_data: dict) -> str:
        """åˆ†æå¸‚åœºè¡Œä¸ºå¹¶ç”ŸæˆAIæŠ¥å‘Š"""
        price_data = {}
        for period, hours in [('1h', 1), ('4h', 4), ('1d', 24)]:
            df = get_binance_klines(symbol, period, limit=2)
            if not df.empty:
                price_change = ((float(df['close'].iloc[-1]) - float(df['open'].iloc[0])) 
                              / float(df['open'].iloc[0])) * 100
                price_data[f'{hours}h_change'] = price_change

        daily_klines = get_binance_klines(symbol, '1d', limit=1)
        volatility = 0
        if not daily_klines.empty:
            high = float(daily_klines['high'].iloc[0])
            low = float(daily_klines['low'].iloc[0])
            volatility = ((high - low) / low) * 100

        prompt = f"""
        ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æœŸè´§äº¤æ˜“åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹{symbol}çš„æ•°æ®è¿›è¡Œæ·±åº¦å¸‚åœºè¡Œä¸ºåˆ†æï¼š

        å½“å‰å¸‚åœºçŠ¶æ€ï¼š
        - å½“å‰æŒä»“é‡ï¼š{position_data['current_oi']:,.0f}
        - æŒä»“åˆ†ä½æ•°ï¼š{position_data['percentile']:.2f}%ï¼ˆé«˜ä½>80%ï¼Œä½ä½<20%ï¼‰
        - 24å°æ—¶æ³¢åŠ¨ç‡ï¼š{volatility:.2f}%

        ä»·æ ¼ä¸æŒä»“é‡å˜åŒ–å¯¹æ¯”ï¼š
        1å°æ—¶å‘¨æœŸï¼š
        - ä»·æ ¼å˜åŒ–ï¼š{price_data.get('1h_change', 0):.2f}%
        - æŒä»“å˜åŒ–ï¼š{position_data['changes']['1å°æ—¶']['change_percentage']:.2f}%
        4å°æ—¶å‘¨æœŸï¼š
        - ä»·æ ¼å˜åŒ–ï¼š{price_data.get('4h_change', 0):.2f}%
        - æŒä»“å˜åŒ–ï¼š{position_data['changes']['4å°æ—¶']['change_percentage']:.2f}%
        24å°æ—¶å‘¨æœŸï¼š
        - ä»·æ ¼å˜åŒ–ï¼š{price_data.get('24h_change', 0):.2f}%
        - æŒä»“å˜åŒ–ï¼š{position_data['changes']['24å°æ—¶']['change_percentage']:.2f}%

        è¯·æä¾›ä»¥ä¸‹åˆ†æï¼ˆä½¿ç”¨markdownæ ¼å¼ï¼‰ï¼š
        ## å¸‚åœºè¡Œä¸ºåˆ†æ
        [åŸºäºä»·æ ¼ä¸æŒä»“é‡çš„å˜åŒ–å…³ç³»åˆ†æ]
        ## æŒä»“æ°´å¹³ç ”åˆ¤
        [åˆ†æå½“å‰æŒä»“é‡æ°´å¹³]
        ## å¤šç©ºåšå¼ˆåˆ†æ
        - ä¸»å¯¼æ–¹å‘ï¼š
        - ä¸»è¦ç‰¹å¾ï¼š
        - å¸‚åœºæƒ…ç»ªï¼š
        ## äº¤æ˜“å»ºè®®
        - æ“ä½œæ€è·¯ï¼š
        - å…³æ³¨é‡ç‚¹ï¼š
        - é£é™©æç¤ºï¼š
        """
        try:
            response = client.chat.completions.create(
                model="grok-3-reasoner",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ç”ŸæˆAIåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            return "AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    def generate_position_report(self, df: pd.DataFrame) -> str:
        """ç”ŸæˆæŒä»“åˆ†æAIæŠ¥å‘Š"""
        df['change_percentage'] = df.apply(lambda x: x['changes']['24å°æ—¶']['change_percentage'], axis=1)
        top_increase = df.nlargest(10, 'change_percentage')
        top_decrease = df.nsmallest(10, 'change_percentage')

        prompt = f"""ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æœŸè´§äº¤æ˜“åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æŒä»“æ•°æ®å˜åŒ–æä¾›ç®€æ´çš„å¸‚åœºåˆ†ææŠ¥å‘Šï¼š
        æŒä»“å¢åŠ æœ€æ˜¾è‘—çš„å‰10ä¸ªäº¤æ˜“å¯¹ï¼š
        {top_increase[['symbol', 'change_percentage']].to_string()}
        æŒä»“å‡å°‘æœ€æ˜¾è‘—çš„å‰10ä¸ªäº¤æ˜“å¯¹ï¼š
        {top_decrease[['symbol', 'change_percentage']].to_string()}
        è¯·æä¾›ä»¥ä¸‹åˆ†æï¼ˆä½¿ç”¨markdownæ ¼å¼ï¼‰ï¼š
        ## å¸‚åœºæƒ…ç»ªåˆ†æ
        [åˆ†ææ•´ä½“å¸‚åœºæƒ…ç»ª]
        ## ä¸»è¦å˜åŠ¨è§£è¯»
        - å¤§é¢æŒä»“å˜åŠ¨åˆ†æ
        - æ½œåœ¨å¸‚åœºæ–¹å‘
        ## äº¤æ˜“å»ºè®®
        - é‡ç‚¹å…³æ³¨å“ç§
        - é£é™©æç¤º
        """
        try:
            response = client.chat.completions.create(
                model="grok-3-reasoner",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ç”ŸæˆæŒä»“åˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            return "AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

def multi_timeframe_analysis(symbol: str) -> dict:
    """å¤šå‘¨æœŸåˆ†æåŠŸèƒ½"""
    results = {}
    trends = {}
    for tf, info in TIMEFRAMES.items():
        df = get_binance_klines(symbol, info['interval'], limit=100)
        if df.empty:
            logger.warning(f"æ—¶é—´å‘¨æœŸ {tf} æ•°æ®è·å–å¤±è´¥")
            continue

        df['rsi'] = calculate_rsi(df['close'])
        support, resistance = calculate_support_resistance(df)
        sma20 = df['close'].rolling(window=20).mean()
        sma50 = df['close'].rolling(window=50).mean()
        current_price = float(df['close'].iloc[-1])

        if current_price > sma20.iloc[-1] > sma50.iloc[-1]:
            trend = "ä¸Šå‡"
        elif current_price < sma20.iloc[-1] < sma50.iloc[-1]:
            trend = "ä¸‹é™"
        else:
            trend = "éœ‡è¡"

        volume_sma = df['volume'].rolling(window=20).mean()
        volume_trend = "æ”¾é‡" if df['volume'].iloc[-1] > volume_sma.iloc[-1] else "ç¼©é‡"

        trends[tf] = {
            "trend": trend,
            "rsi": df['rsi'].iloc[-1],
            "support": support,
            "resistance": resistance,
            "volume_trend": volume_trend
        }

    if not trends:
        return {"error": "æ— æ³•è·å–ä»»ä½•æ—¶é—´å‘¨æœŸçš„æ•°æ®"}

    df_current = get_binance_klines(symbol, '1m', limit=1)
    if df_current.empty or 'close' not in df_current.columns:
        logger.error(f"è·å–å½“å‰ä»·æ ¼å¤±è´¥: æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘'close'åˆ—")
        return {"error": "æ— æ³•è·å–å½“å‰ä»·æ ¼æ•°æ®"}
    current_price = float(df_current['close'].iloc[0])

    short_term_trend = trends.get('5m', {}).get('trend', '') + "/" + trends.get('15m', {}).get('trend', '')
    medium_term_trend = trends.get('1h', {}).get('trend', '') + "/" + trends.get('4h', {}).get('trend', '')
    rsi_values = [data['rsi'] for data in trends.values()]
    avg_rsi = sum(rsi_values) / len(rsi_values) if rsi_values else 0

    risk = {"level": "ä¸­ç­‰", "factors": []}
    if avg_rsi > 70:
        risk["factors"].append("RSIè¶…ä¹°")
    elif avg_rsi < 30:
        risk["factors"].append("RSIè¶…å–")

    for tf, data in trends.items():
        if abs(current_price - data['resistance']) / current_price < 0.02:
            risk["factors"].append(f"{TIMEFRAMES[tf]['name']}æ¥è¿‘é˜»åŠ›ä½")
        if abs(current_price - data['support']) / current_price < 0.02:
            risk["factors"].append(f"{TIMEFRAMES[tf]['name']}æ¥è¿‘æ”¯æ’‘ä½")

    risk["level"] = "é«˜" if len(risk["factors"]) >= 3 else "ä½" if len(risk["factors"]) <= 1 else "ä¸­ç­‰"

    prompt = f"""ä½œä¸ºä¸“ä¸šçš„åŠ å¯†è´§å¸åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®æä¾›è¯¦ç»†çš„å¸‚åœºåˆ†ææŠ¥å‘Šï¼š
    æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼š
    - å½“å‰ä»·æ ¼ï¼š{current_price}
    - çŸ­æœŸè¶‹åŠ¿ï¼š{short_term_trend}
    - ä¸­æœŸè¶‹åŠ¿ï¼š{medium_term_trend}
    - RSIæŒ‡æ ‡ï¼š{avg_rsi:.2f}
    - æ”¯æ’‘ä½ï¼š{trends['1h']['support']}
    - é˜»åŠ›ä½ï¼š{trends['1h']['resistance']}
    - æˆäº¤é‡è¶‹åŠ¿ï¼š{trends['1h']['volume_trend']}
    é£é™©è¯„ä¼°ï¼š
    - é£é™©ç­‰çº§ï¼š{risk['level']}
    - é£é™©å› ç´ ï¼š{', '.join(risk['factors']) if risk['factors'] else 'æ— é‡å¤§é£é™©'}
    è¯·æä¾›ä»¥ä¸‹åˆ†æï¼ˆä½¿ç”¨markdownæ ¼å¼ï¼‰ï¼š
    ## å¸‚åœºç»¼è¿°
    [åŸºäºå¤šå‘¨æœŸåˆ†ææ¡†æ¶çš„æ•´ä½“åˆ¤æ–­]
    ## æŠ€æœ¯é¢åˆ†æ
    - è¶‹åŠ¿çŠ¶æ€ï¼š
    - æ”¯æ’‘é˜»åŠ›åˆ†æï¼š
    - åŠ¨é‡æŒ‡æ ‡è§£è¯»ï¼š
    - æˆäº¤é‡åˆ†æï¼š
    ## æ“ä½œå»ºè®®
    - çŸ­æœŸç­–ç•¥ï¼š
    - ä¸­æœŸå¸ƒå±€ï¼š
    - é£é™©æç¤ºï¼š
    è¯·ç¡®ä¿åˆ†æä¸“ä¸šã€å®¢è§‚ï¼Œå¹¶æ³¨æ„é£é™©æç¤ºã€‚
    """
    try:
        response = client.chat.completions.create(
            model="grok-3-reasoner",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=1000
        )
        ai_analysis = response.choices[0].message.content
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤šå‘¨æœŸåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
        ai_analysis = "AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    return {
        "current_price": current_price,
        "trends": trends,
        "risk": risk,
        "ai_analysis": ai_analysis
    }

class FundFlowAnalyzer:
    """èµ„é‡‘æµå‘åˆ†æå™¨"""
    def __init__(self):
        self.spot_base_url = "https://api.binance.com/api/v3"
        self.futures_base_url = "https://fapi.binance.com/fapi/v1"
        self.stablecoins = {'USDC', 'TUSD', 'BUSD', 'DAI', 'USDP', 'EUR', 'GYEN'}

    def get_all_usdt_symbols(self, is_futures=False):
        """è·å–æ‰€æœ‰ä»¥USDTç»“å°¾çš„äº¤æ˜“å¯¹ï¼Œå‰”é™¤ç¨³å®šå¸å¯¹"""
        base_url = self.futures_base_url if is_futures else self.spot_base_url
        endpoint = "/exchangeInfo"
        response = requests.get(f"{base_url}{endpoint}")
        data = response.json()
        symbols = []
        if is_futures:
            for item in data['symbols']:
                symbol = item['symbol']
                base_asset = item['baseAsset']
                if (item['status'] == 'TRADING' and
                    item['quoteAsset'] == 'USDT' and
                    base_asset not in self.stablecoins):
                    symbols.append(symbol)
        else:
            for item in data['symbols']:
                symbol = item['symbol']
                base_asset = item['baseAsset']
                if (item['status'] == 'TRADING' and
                    item['quoteAsset'] == 'USDT' and
                    base_asset not in self.stablecoins):
                    symbols.append(symbol)
        return symbols

    def format_number(self, value):
        """å°†æ•°å€¼æ ¼å¼åŒ–ä¸ºK/Mè¡¨ç¤ºï¼Œä¿ç•™ä¸¤ä½å°æ•°"""
        if abs(value) >= 1000000:
            return f"{value / 1000000:.2f}M"
        elif abs(value) >= 1000:
            return f"{value / 1000:.2f}K"
        else:
            return f"{value:.2f}"

    def get_klines_parallel(self, symbols, is_futures=False, max_workers=20):
        """ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè·å–å¤šä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®ï¼ˆä½¿ç”¨å€’æ•°ç¬¬äºŒæ ¹å·²å®Œæˆçš„æ—¥çº¿èœ¡çƒ›å›¾ï¼‰"""
        results = []
        def fetch_kline(symbol):
            try:
                base_url = self.futures_base_url if is_futures else self.spot_base_url
                endpoint = "/klines"
                now = datetime.utcnow()
                today_start = datetime(now.year, now.month, now.day, 0, 0, 0)
                end_time = int(today_start.timestamp() * 1000)
                start_time = int((today_start - timedelta(days=2)).timestamp() * 1000)
                params = {
                    'symbol': symbol,
                    'interval': '4h',
                    'startTime': start_time,
                    'endTime': end_time,
                    'limit': 2
                }
                response = requests.get(f"{base_url}{endpoint}", params=params)
                data = response.json()
                if not data or len(data) < 2:
                    logger.error(f"Insufficient data for {symbol}: {len(data)} candles returned")
                    return None
                k = data[1]  # ä½¿ç”¨å€’æ•°ç¬¬ä¸€æ ¹å·²å®ŒæˆKçº¿
                open_time = datetime.fromtimestamp(k[0] / 1000).strftime('%Y-%m-%d %H:%M:%S')
                close_time = datetime.fromtimestamp(k[6] / 1000).strftime('%Y-%m-%d %H:%M:%S')
                return {
                    'symbol': symbol,
                    'open_time': open_time,
                    'close_time': close_time,
                    'open': float(k[1]),
                    'high': float(k[2]),
                    'low': float(k[3]),
                    'close': float(k[4]),
                    'volume': float(k[5]),
                    'quote_volume': float(k[7]),
                    'trades': int(k[8]),
                    'taker_buy_base_volume': float(k[9]),
                    'taker_buy_quote_volume': float(k[10]),
                    'net_inflow': 2 * float(k[10]) - float(k[7])
                }
            except Exception as e:
                logger.error(f"Error fetching {symbol}: {e}")
                return None
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(fetch_kline, symbol): symbol for symbol in symbols}
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result:
                    results.append(result)
        return results

    def send_to_deepseek(self, data):
        prompt = (
            "ä»¥ä¸‹æ˜¯Binanceç°è´§å’ŒæœŸè´§å¸‚åœºä¸­USDTäº¤æ˜“å¯¹çš„èµ„é‡‘æµå…¥æµå‡ºæ•°æ®ï¼ˆåŸºäºå‰ä¸€å¤©çš„å·²å®Œæˆæ—¥çº¿æ•°æ®ï¼‰ï¼Œè¯·åˆ†æï¼š\n"
            "1. æœŸè´§å’Œç°è´§å¸‚åœºä¸­å‡ºç°çš„ç›¸åŒäº¤æ˜“å¯¹åŠå…¶æµå…¥æµå‡ºæƒ…å†µã€‚\n"
            "2. ä»èµ„é‡‘æµè§’åº¦è§£è¯»è¿™äº›æ•°æ®ï¼Œå¯èƒ½çš„å¸‚åœºè¶‹åŠ¿æˆ–äº¤æ˜“ä¿¡å·ã€‚\n"
            "3. æä¾›ä¸“ä¸šçš„èµ„é‡‘åˆ†æè§†è§’ï¼Œä¾‹å¦‚å¤§èµ„é‡‘åŠ¨å‘ã€æ½œåœ¨çš„å¸‚åœºæ“çºµè¿¹è±¡ç­‰ã€‚\n"
            "æ•°æ®å¦‚ä¸‹ï¼š\n" + json.dumps(data, indent=2, ensure_ascii=False) +
            "\nè¯·ä»¥ä¸­æ–‡å›å¤ï¼Œå°½é‡ç®€æ´ä½†ä¸“ä¸šã€‚"
        )
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"DeepSeek API error: {e}")
            return "æ— æ³•è·å–DeepSeekåˆ†æç»“æœ"

    def analyze_fund_flow(self):
        """åˆ†æèµ„é‡‘æµå‘"""
        spot_symbols = self.get_all_usdt_symbols(is_futures=False)
        futures_symbols = self.get_all_usdt_symbols(is_futures=True)
        spot_data = self.get_klines_parallel(spot_symbols, is_futures=False, max_workers=20)
        futures_data = self.get_klines_parallel(futures_symbols, is_futures=True, max_workers=20)
        spot_df = pd.DataFrame(spot_data)
        futures_df = pd.DataFrame(futures_data)
        spot_inflow_top20 = spot_df.sort_values(by='net_inflow', ascending=False).head(20)
        futures_inflow_top20 = futures_df.sort_values(by='net_inflow', ascending=False).head(20)
        spot_outflow_top20 = spot_df.sort_values(by='net_inflow', ascending=True).head(20)
        futures_outflow_top20 = futures_df.sort_values(by='net_inflow', ascending=True).head(20)
        deepseek_data = {
            "spot_inflow_top20": spot_inflow_top20[['symbol', 'net_inflow', 'quote_volume']].to_dict('records'),
            "futures_inflow_top20": futures_inflow_top20[['symbol', 'net_inflow', 'quote_volume']].to_dict('records'),
            "spot_outflow_top20": spot_outflow_top20[['symbol', 'net_inflow', 'quote_volume']].to_dict('records'),
            "futures_outflow_top20": futures_outflow_top20[['symbol', 'net_inflow', 'quote_volume']].to_dict('records')
        }
        analysis = self.send_to_deepseek(deepseek_data)
        return {
            "spot_inflow_top20": spot_inflow_top20,
            "futures_inflow_top20": futures_inflow_top20,
            "spot_outflow_top20": spot_outflow_top20,
            "futures_outflow_top20": futures_outflow_top20,
            "analysis": analysis
        }

def main():
    st.title("åˆ†æç³»ç»Ÿ")
    st.sidebar.header("åŠŸèƒ½å¯¼èˆª")
    if 'current_analysis' not in st.session_state:
        st.session_state.current_analysis = "å¸‚åœºè¡Œä¸ºåˆ†æ"

    if st.sidebar.button("å¸‚åœºè¡Œä¸ºåˆ†æ",
                         type="primary" if st.session_state.current_analysis == "å¸‚åœºè¡Œä¸ºåˆ†æ" else "secondary",
                         use_container_width=True):
        st.session_state.current_analysis = "å¸‚åœºè¡Œä¸ºåˆ†æ"
    if st.sidebar.button("æŒä»“åˆ†æ",
                         type="primary" if st.session_state.current_analysis == "æŒä»“åˆ†æ" else "secondary",
                         use_container_width=True):
        st.session_state.current_analysis = "æŒä»“åˆ†æ"
    if st.sidebar.button("å¤šå‘¨æœŸåˆ†æ",
                         type="primary" if st.session_state.current_analysis == "å¤šå‘¨æœŸåˆ†æ" else "secondary",
                         use_container_width=True):
        st.session_state.current_analysis = "å¤šå‘¨æœŸåˆ†æ"
    if st.sidebar.button("èµ„é‡‘æµå‘åˆ†æ",
                         type="primary" if st.session_state.current_analysis == "èµ„é‡‘æµå‘åˆ†æ" else "secondary",
                         use_container_width=True):
        st.session_state.current_analysis = "èµ„é‡‘æµå‘åˆ†æ"

    if st.session_state.current_analysis == "å¸‚åœºè¡Œä¸ºåˆ†æ":
        st.header("å¸‚åœºè¡Œä¸ºåˆ†æ")
        analyzer = BinanceFuturesAnalyzer()
        symbols = analyzer.get_usdt_symbols()
        selected_symbol = st.selectbox("é€‰æ‹©äº¤æ˜“å¯¹", symbols)
        if st.button("å¼€å§‹åˆ†æ"):
            with st.spinner("æ­£åœ¨åˆ†æå¸‚åœºè¡Œä¸º..."):
                position_data = analyzer.get_open_interest(selected_symbol)
                if position_data and position_data['data']:
                    df = pd.DataFrame(position_data['data'])
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                    df['sumOpenInterest'] = df['sumOpenInterest'].astype(float)
                    current_oi = float(df['sumOpenInterest'].iloc[-1])
                    percentile = (df['sumOpenInterest'].rank(pct=True).iloc[-1]) * 100
                    changes = {}
                    for period, hours in [('1å°æ—¶', 1), ('4å°æ—¶', 4), ('24å°æ—¶', 24)]:
                        past_oi = float(df[df['timestamp'] <=
                                         df['timestamp'].max() - pd.Timedelta(hours=hours)]
                                      ['sumOpenInterest'].iloc[-1])
                        change = current_oi - past_oi
                        change_percentage = (change / past_oi) * 100
                        changes[period] = {'change': change, 'change_percentage': change_percentage}
                    position_info = {'current_oi': current_oi, 'percentile': percentile, 'changes': changes}
                    analysis_report = analyzer.analyze_market_behavior(selected_symbol, position_info)
                    st.markdown(analysis_report)

    elif st.session_state.current_analysis == "æŒä»“åˆ†æ":
        st.header("æŒä»“åˆ†æ")
        analyzer = BinanceFuturesAnalyzer()
        if st.button("åˆ†ææ‰€æœ‰äº¤æ˜“å¯¹æŒä»“"):
            with st.spinner("æ­£åœ¨åˆ†ææŒä»“æ•°æ®..."):
                df = analyzer.analyze_positions()
                st.subheader("æŒä»“å˜åŒ–Top10")
                increase_top10 = df.nlargest(10, 'change_percentage')[['symbol', 'change_percentage', 'current_oi']]
                decrease_top10 = df.nsmallest(10, 'change_percentage')[['symbol', 'change_percentage', 'current_oi']]
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**å¢æŒTop10**")
                    increase_display = increase_top10.copy()
                    increase_display.columns = ['äº¤æ˜“å¯¹', 'å˜åŒ–ç‡(%)', 'å½“å‰æŒä»“']
                    increase_display['å˜åŒ–ç‡(%)'] = increase_display['å˜åŒ–ç‡(%)'].round(2)
                    increase_display['å½“å‰æŒä»“'] = increase_display['å½“å‰æŒä»“'].round(2)
                    st.table(increase_display)
                with col2:
                    st.markdown("**å‡æŒTop10**")
                    decrease_display = decrease_top10.copy()
                    decrease_display.columns = ['äº¤æ˜“å¯¹', 'å˜åŒ–ç‡(%)', 'å½“å‰æŒä»“']
                    decrease_display['å˜åŒ–ç‡(%)'] = decrease_display['å˜åŒ–ç‡(%)'].round(2)
                    decrease_display['å½“å‰æŒä»“'] = decrease_display['å½“å‰æŒä»“'].round(2)
                    st.table(decrease_display)
                st.subheader("æ€»ä½“æŒä»“åˆ†æ")
                report = analyzer.generate_position_report(df)
                st.markdown(report)

    elif st.session_state.current_analysis == "å¤šå‘¨æœŸåˆ†æ":
        st.header("å¤šå‘¨æœŸåˆ†æ")
        analyzer = BinanceFuturesAnalyzer()
        symbols = analyzer.get_usdt_symbols()
        selected_symbol = st.selectbox("é€‰æ‹©äº¤æ˜“å¯¹", symbols)
        if st.button("å¼€å§‹å¤šå‘¨æœŸåˆ†æ"):
            with st.spinner("æ­£åœ¨è¿›è¡Œå¤šå‘¨æœŸåˆ†æ..."):
                analysis_result = multi_timeframe_analysis(selected_symbol)
                if "error" in analysis_result:
                    st.error(analysis_result["error"])
                else:
                    st.markdown(analysis_result["ai_analysis"])

    elif st.session_state.current_analysis == "èµ„é‡‘æµå‘åˆ†æ":
        st.header("èµ„é‡‘æµå‘åˆ†æ")
        fund_flow_analyzer = FundFlowAnalyzer()
        if st.button("å¼€å§‹èµ„é‡‘æµå‘åˆ†æ"):
            with st.spinner("æ­£åœ¨åˆ†æèµ„é‡‘æµå‘..."):
                analysis_result = fund_flow_analyzer.analyze_fund_flow()
                st.subheader("ç°è´§äº¤æ˜“å¯¹å‡€æµå…¥TOP20")
                st.table(analysis_result["spot_inflow_top20"][['symbol', 'net_inflow', 'quote_volume']])
                st.subheader("æœŸè´§äº¤æ˜“å¯¹å‡€æµå…¥TOP20")
                st.table(analysis_result["futures_inflow_top20"][['symbol', 'net_inflow', 'quote_volume']])
                st.subheader("ç°è´§äº¤æ˜“å¯¹å‡€æµå‡ºTOP20")
                st.table(analysis_result["spot_outflow_top20"][['symbol', 'net_inflow', 'quote_volume']])
                st.subheader("æœŸè´§äº¤æ˜“å¯¹å‡€æµå‡ºTOP20")
                st.table(analysis_result["futures_outflow_top20"][['symbol', 'net_inflow', 'quote_volume']])
                st.subheader("DeepSeekåˆ†æç»“æœ")
                st.markdown(analysis_result["analysis"])

if __name__ == "__main__":
    main()
